{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Stage 2 Usage Examples (LangChain Reasoning & Router)\n",
        "\n",
        "This notebook demonstrates how to use the Stage 2 chains to query the synthetic payments dataset and obtain concise summaries.\n",
        "\n",
        "- Routed Q&A via `router_chain.ask()`\n",
        "- Direct code generation and execution via `query_chain`\n",
        "- Summarization via `summary_chain`\n",
        "- Optional: enabling LLM with `OPENAI_API_KEY` (otherwise heuristic fallback is used)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# optional: load .env for local development\n",
        "#%pip install -q python-dotenv\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()  # loads variables from .env into the process env\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import logging\n",
        "logging.basicConfig(level=logging.INFO, format='[%(name)s] %(levelname)s: %(message)s')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Project root: /home/andres/Documents/chat-payments\n",
            "OPENAI_API_KEY set: True\n",
            "Data path: /home/andres/Documents/chat-payments/data/payments.csv\n"
          ]
        }
      ],
      "source": [
        "# Setup imports and paths\n",
        "import os, sys\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "\n",
        "# Ensure project root on path\n",
        "PROJECT_ROOT = str(Path.cwd().parent)\n",
        "if PROJECT_ROOT not in sys.path:\n",
        "    sys.path.append(PROJECT_ROOT)\n",
        "\n",
        "print('Project root:', PROJECT_ROOT)\n",
        "print('OPENAI_API_KEY set:', bool(os.getenv('OPENAI_API_KEY')))\n",
        "\n",
        "DATA_PATH = str(Path(PROJECT_ROOT) / 'data' / 'payments.csv')\n",
        "print('Data path:', DATA_PATH)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# print(\"LLM_PROVIDER =\", os.getenv(\"LLM_PROVIDER\"))\n",
        "# print(\"LLM_MODEL    =\", os.getenv(\"LLM_MODEL\"))\n",
        "# print(\"GROQ_API_KEY set?\", bool(os.getenv(\"GROQ_API_KEY\")))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# provider = \"groq\"\n",
        "# model = \"llama-3.3-70b-versatile\"\n",
        "\n",
        "os.environ[\"LLM_PROVIDER\"] = \"groq\"\n",
        "os.environ[\"LLM_MODEL\"] = \"llama-3.3-70b-versatile\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[src.chains.query_chain] INFO: QueryChain initialized with LLM provider=groq model=llama-3.3-70b-versatile\n",
            "[src.chains.query_chain] INFO: QueryChain using LLM for question: Quick test?\n",
            "[httpx] INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "[src.chains.summary_chain] INFO: SummaryChain initialized with LLM provider=groq model=llama-3.3-70b-versatile\n",
            "[src.chains.summary_chain] INFO: SummaryChain using LLM for question: Quick test?\n",
            "[httpx] INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[router] llm_used=True provider=groq model=llama-3.3-70b-versatile\n",
            "{'latency_ms': 2077, 'llm_used': True, 'llm_provider': 'groq', 'llm_model': 'llama-3.3-70b-versatile'}\n"
          ]
        }
      ],
      "source": [
        "from src.chains.router_chain import ask\n",
        "# resp = ask(\"Quick test?\", provider=provider, model=model)\n",
        "resp = ask(\"Quick test?\")\n",
        "print(resp[\"metrics\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rows: 10,000 | Columns: 11\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>transaction_id</th>\n",
              "      <th>user_id</th>\n",
              "      <th>segment</th>\n",
              "      <th>country</th>\n",
              "      <th>merchant</th>\n",
              "      <th>category</th>\n",
              "      <th>amount</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>device_type</th>\n",
              "      <th>is_refunded</th>\n",
              "      <th>is_fraudulent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>879463009885</td>\n",
              "      <td>208</td>\n",
              "      <td>SMB</td>\n",
              "      <td>AR</td>\n",
              "      <td>Microsoft</td>\n",
              "      <td>electronics</td>\n",
              "      <td>126.02</td>\n",
              "      <td>2023-01-01 01:04:39+00:00</td>\n",
              "      <td>tablet</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>404737561214</td>\n",
              "      <td>183</td>\n",
              "      <td>consumer</td>\n",
              "      <td>US</td>\n",
              "      <td>Telcel</td>\n",
              "      <td>telco</td>\n",
              "      <td>48.31</td>\n",
              "      <td>2023-01-01 03:08:19+00:00</td>\n",
              "      <td>tablet</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>12503321040</td>\n",
              "      <td>155</td>\n",
              "      <td>consumer</td>\n",
              "      <td>BR</td>\n",
              "      <td>Oxxo</td>\n",
              "      <td>retail</td>\n",
              "      <td>10.56</td>\n",
              "      <td>2023-01-01 08:52:04+00:00</td>\n",
              "      <td>mobile</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   transaction_id  user_id   segment country   merchant     category  amount  \\\n",
              "0    879463009885      208       SMB      AR  Microsoft  electronics  126.02   \n",
              "1    404737561214      183  consumer      US     Telcel        telco   48.31   \n",
              "2     12503321040      155  consumer      BR       Oxxo       retail   10.56   \n",
              "\n",
              "                  timestamp device_type  is_refunded  is_fraudulent  \n",
              "0 2023-01-01 01:04:39+00:00      tablet        False          False  \n",
              "1 2023-01-01 03:08:19+00:00      tablet        False          False  \n",
              "2 2023-01-01 08:52:04+00:00      mobile        False          False  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load dataset preview\n",
        "df = pd.read_csv(DATA_PATH, parse_dates=['timestamp'])\n",
        "print(f\"Rows: {len(df):,} | Columns: {len(df.columns)}\")\n",
        "df.head(3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[src.chains.query_chain] INFO: QueryChain initialized with LLM provider=groq model=llama-3.3-70b-versatile\n",
            "[src.chains.query_chain] INFO: QueryChain using LLM for question: Which merchants had the highest total revenue last month?\n",
            "[httpx] INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "[src.chains.summary_chain] INFO: SummaryChain initialized with LLM provider=groq model=llama-3.3-70b-versatile\n",
            "[src.chains.summary_chain] INFO: SummaryChain using LLM for question: Which merchants had the highest total revenue last month?\n",
            "[httpx] INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[router] llm_used=True provider=groq model=llama-3.3-70b-versatile\n",
            "Route: data\n",
            "Answer: BestBuy led last month with $1,719.16 in revenue, followed by Apple at $1,600.81, and Delta at $1,307.85.\n"
          ]
        }
      ],
      "source": [
        "# Example 1: Routed data Q&A\n",
        "\n",
        "q1 = \"Which merchants had the highest total revenue last month?\"\n",
        "# resp1 = ask(q1, provider=provider, model=model)\n",
        "resp1 = ask(q1)\n",
        "print('Route:', resp1['route'])\n",
        "print('Answer:', resp1['answer'])\n",
        "\n",
        "# Convert table (list of dicts) back into a DataFrame for display\n",
        "if resp1.get('table'):\n",
        "    pd.DataFrame(resp1['table']).head(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[src.chains.query_chain] INFO: QueryChain initialized with LLM provider=groq model=llama-3.3-70b-versatile\n",
            "[src.chains.query_chain] INFO: QueryChain using LLM for question: Which country has the highest average transaction amount?\n",
            "[httpx] INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "[src.chains.summary_chain] INFO: SummaryChain initialized with LLM provider=groq model=llama-3.3-70b-versatile\n",
            "[src.chains.summary_chain] INFO: SummaryChain using LLM for question: Which country has the highest average transaction amount?\n",
            "[httpx] INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[router] llm_used=True provider=groq model=llama-3.3-70b-versatile\n",
            "Route: data\n",
            "Answer: The US has the highest average transaction amount at $49.84.\n"
          ]
        }
      ],
      "source": [
        "# Example 2: Another routed question\n",
        "q2 = \"Which country has the highest average transaction amount?\"\n",
        "# resp2 = ask(q2, provider=provider, model=model)\n",
        "resp2 = ask(q2)\n",
        "print('Route:', resp2['route'])\n",
        "print('Answer:', resp2['answer'])\n",
        "\n",
        "if resp2.get('table'):\n",
        "    pd.DataFrame(resp2['table']).head(10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Tendría que usar QueryChain en lugar de esto?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[src.chains.query_chain] INFO: QueryChain initialized with LLM provider=groq model=llama-3.3-70b-versatile\n",
            "[src.chains.query_chain] INFO: QueryChain using LLM for question: Top 10 merchants by total revenue\n",
            "[httpx] INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Keys: ['answer', 'table']\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>merchant</th>\n",
              "      <th>amount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Apple</td>\n",
              "      <td>75567.62</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>BestBuy</td>\n",
              "      <td>57285.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Microsoft</td>\n",
              "      <td>41248.78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Delta</td>\n",
              "      <td>34953.35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Airbnb</td>\n",
              "      <td>32691.88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Amazon</td>\n",
              "      <td>28881.65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Walmart</td>\n",
              "      <td>24177.42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>MercadoLibre</td>\n",
              "      <td>19230.28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Shell</td>\n",
              "      <td>15710.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Alibaba</td>\n",
              "      <td>14354.27</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       merchant    amount\n",
              "0         Apple  75567.62\n",
              "1       BestBuy  57285.50\n",
              "2     Microsoft  41248.78\n",
              "3         Delta  34953.35\n",
              "4        Airbnb  32691.88\n",
              "5        Amazon  28881.65\n",
              "6       Walmart  24177.42\n",
              "7  MercadoLibre  19230.28\n",
              "8         Shell  15710.95\n",
              "9       Alibaba  14354.27"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Example 3: Direct query chain usage\n",
        "from src.chains.query_chain import run as run_query\n",
        "\n",
        "q3 = \"Top 10 merchants by total revenue\"\n",
        "res3 = run_query(q3)\n",
        "\n",
        "print('Keys:', list(res3.keys()))\n",
        "\n",
        "# Reconstruct DataFrame from 'split' orient\n",
        "split = res3['table']\n",
        "df3 = pd.DataFrame(split['data'], columns=split['columns'])\n",
        "df3.head(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[src.chains.summary_chain] INFO: SummaryChain initialized with LLM provider=groq model=llama-3.3-70b-versatile\n",
            "[src.chains.summary_chain] INFO: SummaryChain using LLM for question: Top 10 merchants by total revenue\n",
            "[httpx] INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Apple led with $75.6K in revenue, followed by BestBuy at $57.3K, and Microsoft at $41.2K, rounding out the top 3 of the 10 merchants listed.\n"
          ]
        }
      ],
      "source": [
        "# Example 4: Summarize a result explicitly\n",
        "from src.chains.summary_chain import SummaryChain\n",
        "\n",
        "summary = SummaryChain().run(q3, df3)\n",
        "print(summary)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[src.chains.query_chain] INFO: QueryChain initialized with LLM provider=groq model=llama-3.3-70b-versatile\n",
            "[src.chains.query_chain] INFO: QueryChain using LLM for question: What was the total payment volume last week?\n",
            "[httpx] INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "[src.chains.query_chain] INFO: Retrying with stricter instruction due to exec error: 'numpy.float64' object has no attribute 'to_frame'\n",
            "[httpx] INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "[src.chains.summary_chain] INFO: SummaryChain initialized with LLM provider=groq model=llama-3.3-70b-versatile\n",
            "[src.chains.summary_chain] INFO: SummaryChain using LLM for question: What was the total payment volume last week?\n",
            "[httpx] INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[router] llm_used=True provider=groq model=llama-3.3-70b-versatile\n",
            "Route: data\n",
            "Answer: The total payment volume last week was approximately $2,993.80.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_237816/4134056275.py:13: RuntimeWarning: coroutine 'ask_async' was never awaited\n",
            "  resp = ask(q)\n",
            "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
          ]
        }
      ],
      "source": [
        "# Example 5 (optional): Async ask()\n",
        "# If the notebook environment has an event loop, fallback to sync.\n",
        "try:\n",
        "    import asyncio\n",
        "    from src.chains.router_chain import ask_async\n",
        "    \n",
        "    def run_async_example():\n",
        "        q = \"What was the total payment volume last week?\"\n",
        "        try:\n",
        "            resp = asyncio.run(ask_async(q))\n",
        "        except RuntimeError:\n",
        "            # Fallback if event loop is already running\n",
        "            resp = ask(q)\n",
        "        print('Route:', resp['route'])\n",
        "        print('Answer:', resp['answer'])\n",
        "        return resp\n",
        "    \n",
        "    _ = run_async_example()\n",
        "except Exception as e:\n",
        "    print('Async example skipped:', e)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
